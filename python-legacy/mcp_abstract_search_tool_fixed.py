#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MCP (Model Context Protocol) ì´ˆë¡ ê²€ìƒ‰ ë„êµ¬ - ìˆ˜ì •ëœ ë²„ì „
LLMì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë…¼ë¬¸ ê²€ìƒ‰ ë° ì´ˆë¡ ê°€ì ¸ì˜¤ê¸° ë„êµ¬
"""

import asyncio
import json
import time
import pandas as pd
import urllib3
import re
from typing import Dict, List, Optional, Any
from urllib.parse import quote

# SSL ê²½ê³  ë¹„í™œì„±í™”
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class MCPAbstractSearchTool:
    """MCP ì´ˆë¡ ê²€ìƒ‰ ë„êµ¬"""
    
    def __init__(self):
        self.scopus_api_key = "920a284740d2c60fc3249e6e795e928c"
        self.scopus_url = "https://api.elsevier.com/content/search/scopus"
        self.sources = {
            'crossref': 'https://api.crossref.org/works',
            'pubmed': 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils',
            'semantic_scholar': 'https://api.semanticscholar.org/v1'
        }
        
        self.headers = {
            'Accept': 'application/json',
            'X-ELS-APIKey': self.scopus_api_key
        }
    
    def clean_abstract(self, abstract: str) -> str:
        """ì´ˆë¡ í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not abstract or abstract == 'N/A':
            return 'N/A'
        
        # HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', abstract)
        clean_text = re.sub(r'<jats:[^>]+>', '', clean_text)
        clean_text = re.sub(r'</jats:[^>]+>', '', clean_text)
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        clean_text = re.sub(r'\s+', ' ', clean_text)
        clean_text = clean_text.strip()
        
        # ê¸¸ì´ ì œí•œ (500ì)
        if len(clean_text) > 500:
            clean_text = clean_text[:500] + "..."
        
        return clean_text
    
    def search_scopus(self, query: str, count: int = 10) -> Dict:
        """Scopus ê²€ìƒ‰"""
        params = {
            'query': query,
            'count': count,
            'start': 0,
            'apiKey': self.scopus_api_key
        }
        
        try:
            import requests
            response = requests.get(self.scopus_url, headers=self.headers, params=params, verify=False)
            
            if response.status_code == 200:
                return response.json()
            else:
                return {}
                
        except Exception as e:
            return {}
    
    def get_abstract_from_crossref(self, doi: str) -> Dict:
        """Crossref APIë¡œ ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°"""
        if not doi or doi == 'N/A':
            return {'source': 'crossref', 'abstract': 'N/A', 'success': False}
        
        url = f"{self.sources['crossref']}/{doi}"
        
        try:
            import requests
            response = requests.get(url, verify=False, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if 'message' in data:
                    message = data['message']
                    abstract = message.get('abstract', 'N/A')
                    
                    if abstract and abstract != 'N/A':
                        clean_abstract = self.clean_abstract(abstract)
                        return {
                            'source': 'crossref',
                            'abstract': clean_abstract,
                            'success': True,
                            'title': message.get('title', ['N/A'])[0] if message.get('title') else 'N/A',
                            'quality_score': 9
                        }
            
            return {'source': 'crossref', 'abstract': 'N/A', 'success': False}
            
        except Exception as e:
            return {'source': 'crossref', 'abstract': 'N/A', 'success': False}
    
    def get_abstract_from_pubmed(self, doi: str) -> Dict:
        """PubMed APIë¡œ ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°"""
        if not doi or doi == 'N/A':
            return {'source': 'pubmed', 'abstract': 'N/A', 'success': False}
        
        search_url = f"{self.sources['pubmed']}/esearch.fcgi"
        search_params = {
            'db': 'pubmed',
            'term': f"{doi}[doi]",
            'retmode': 'json'
        }
        
        try:
            import requests
            response = requests.get(search_url, params=search_params, verify=False, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if 'esearchresult' in data and 'idlist' in data['esearchresult']:
                    pmid_list = data['esearchresult']['idlist']
                    
                    if pmid_list:
                        pmid = pmid_list[0]
                        
                        fetch_url = f"{self.sources['pubmed']}/efetch.fcgi"
                        fetch_params = {
                            'db': 'pubmed',
                            'id': pmid,
                            'retmode': 'xml'
                        }
                        
                        fetch_response = requests.get(fetch_url, params=fetch_params, verify=False, timeout=10)
                        
                        if fetch_response.status_code == 200:
                            import xml.etree.ElementTree as ET
                            root = ET.fromstring(fetch_response.content)
                            
                            abstract = root.find('.//AbstractText')
                            if abstract is not None and abstract.text:
                                title = root.find('.//ArticleTitle')
                                title_text = title.text if title is not None else 'N/A'
                                
                                clean_abstract = self.clean_abstract(abstract.text)
                                return {
                                    'source': 'pubmed',
                                    'abstract': clean_abstract,
                                    'success': True,
                                    'title': title_text,
                                    'quality_score': 8
                                }
            
            return {'source': 'pubmed', 'abstract': 'N/A', 'success': False}
            
        except Exception as e:
            return {'source': 'pubmed', 'abstract': 'N/A', 'success': False}
    
    def get_best_abstract(self, doi: str) -> Dict:
        """ìµœê³  í’ˆì§ˆì˜ ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°"""
        results = []
        
        sources = [
            ('crossref', self.get_abstract_from_crossref),
            ('pubmed', self.get_abstract_from_pubmed)
        ]
        
        for source_name, source_func in sources:
            result = source_func(doi)
            if result['success']:
                results.append(result)
            time.sleep(0.3)
        
        if results:
            best_result = max(results, key=lambda x: x.get('quality_score', 0))
            return best_result
        
        return {'source': 'none', 'abstract': 'N/A', 'success': False}
    
    def search_papers_with_abstracts(self, query: str, count: int = 10) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ë…¼ë¬¸ ê²€ìƒ‰í•˜ê³  ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°"""
        results = self.search_scopus(query=query, count=count)
        
        if results and 'search-results' in results:
            total_results = results['search-results'].get('opensearch:totalResults', 0)
            entries = results['search-results'].get('entry', [])
            
            papers = []
            for entry in entries:
                doi = entry.get('prism:doi', 'N/A')
                
                # ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°
                if doi != 'N/A':
                    abstract_result = self.get_best_abstract(doi)
                    abstract = abstract_result['abstract'] if abstract_result['success'] else 'N/A'
                else:
                    abstract = 'N/A'
                    abstract_result = {'source': 'N/A'}
                
                paper = {
                    'title': entry.get('dc:title', 'N/A'),
                    'authors': entry.get('dc:creator', 'N/A'),
                    'publication_name': entry.get('prism:publicationName', 'N/A'),
                    'publication_date': entry.get('prism:coverDate', 'N/A'),
                    'doi': doi,
                    'cited_by_count': entry.get('citedby-count', 0),
                    'scopus_id': entry.get('dc:identifier', '').replace('SCOPUS_ID:', ''),
                    'scopus_url': f"https://www.scopus.com/inward/record.uri?eid={entry.get('eid', '')}",
                    'abstract': abstract,
                    'abstract_source': abstract_result.get('source', 'N/A')
                }
                papers.append(paper)
            
            return papers
        else:
            return []

# MCP ì„œë²„ ì„¤ì •
tool = MCPAbstractSearchTool()

# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_mcp_tool():
    """MCP ë„êµ¬ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” MCP ì´ˆë¡ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ 1: í‚¤ì›Œë“œ ê²€ìƒ‰
    print("1. í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
    papers = tool.search_papers_with_abstracts("artificial intelligence", 3)
    
    if papers:
        print(f"âœ… ì„±ê³µ! {len(papers)}ê°œ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        for i, paper in enumerate(papers, 1):
            print(f"\n[{i}] {paper['title']}")
            print(f"ì €ì: {paper['authors']}")
            print(f"ì´ˆë¡: {paper['abstract'][:100]}...")
    else:
        print("âŒ ê²€ìƒ‰ ì‹¤íŒ¨")
    
    # í…ŒìŠ¤íŠ¸ 2: DOI ê²€ìƒ‰
    print("\n2. DOI ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
    doi = "10.1016/S0014-5793(01)03313-0"
    abstract_result = tool.get_best_abstract(doi)
    
    if abstract_result['success']:
        print(f"âœ… ì„±ê³µ! DOI: {doi}")
        print(f"ì œëª©: {abstract_result.get('title', 'N/A')}")
        print(f"ì´ˆë¡: {abstract_result['abstract'][:100]}...")
    else:
        print(f"âŒ DOI '{doi}'ì— ëŒ€í•œ ì´ˆë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    test_mcp_tool()

if __name__ == "__main__":
    main() 