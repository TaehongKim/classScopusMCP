#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Scopus APIë¥¼ í™œìš©í•œ Usability ë…¼ë¬¸ ê²€ìƒ‰ ì˜ˆì œ
ê¸°ë°˜ ë¬¸ì„œ: Elsevier Scopus APIs Getting Started Guide Version 1 (September 2023)
"""

import requests
import json
import time
from typing import Dict, List, Optional
import pandas as pd


class ScopusAPIClient:
    """Scopus API í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str, base_url: str = "https://api.elsevier.com"):
        """
        Scopus API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            api_key (str): Elsevier API Key
            base_url (str): API ê¸°ë³¸ URL
        """
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            'Accept': 'application/json',
            'X-ELS-APIKey': api_key
        }
    
    def search_scopus(self, query: str, count: int = 25, start: int = 0, 
                     view: str = "STANDARD", sort: str = "relevancy") -> Dict:
        """
        Scopus Search APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¼ë¬¸ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            count (int): ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ìµœëŒ€ 200)
            start (int): ì‹œì‘ ìœ„ì¹˜ (ê¸°ë³¸ê°’: 0)
            view (str): ì‘ë‹µ ë·° (STANDARD ë˜ëŠ” COMPLETE)
            sort (str): ì •ë ¬ ë°©ì‹ (relevancy, citedby-count, coverDate ë“±)
            
        Returns:
            Dict: API ì‘ë‹µ ë°ì´í„°
        """
        endpoint = f"{self.base_url}/content/search/scopus"
        
        params = {
            'query': query,
            'count': count,
            'start': start,
            'view': view,
            'sort': sort,
            'apiKey': self.api_key
        }
        
        try:
            response = requests.get(endpoint, headers=self.headers, params=params)
            
            # Rate limit ì²˜ë¦¬ (ë¬¸ì„œì— ë”°ë¥´ë©´ throttling ì œí•œ ìˆìŒ)
            if response.status_code == 429:
                print("Rate limit exceeded. Waiting 60 seconds...")
                time.sleep(60)
                response = requests.get(endpoint, headers=self.headers, params=params)
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"API ìš”ì²­ ì˜¤ë¥˜: {e}")
            return {}
    
    def get_abstract_details(self, scopus_id: str) -> Dict:
        """
        Abstract Retrieval APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¼ë¬¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        
        Args:
            scopus_id (str): Scopus ë¬¸ì„œ ID
            
        Returns:
            Dict: ë…¼ë¬¸ ìƒì„¸ ì •ë³´
        """
        endpoint = f"{self.base_url}/content/abstract/scopus_id/{scopus_id}"
        
        params = {
            'apiKey': self.api_key,
            'view': 'FULL'
        }
        
        try:
            response = requests.get(endpoint, headers=self.headers, params=params)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"Abstract ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {}
    
    def get_citation_count(self, doi: str) -> Dict:
        """
        Citation Count APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìš© íšŸìˆ˜ ì¡°íšŒ
        
        Args:
            doi (str): ë…¼ë¬¸ì˜ DOI
            
        Returns:
            Dict: ì¸ìš© ì •ë³´
        """
        endpoint = f"{self.base_url}/content/abstract/citation-count"
        
        params = {
            'doi': doi,
            'apiKey': self.api_key
        }
        
        try:
            response = requests.get(endpoint, headers=self.headers, params=params)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"Citation count ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {}


def get_user_search_inputs():
    """ì‚¬ìš©ìë¡œë¶€í„° ê²€ìƒ‰ ì¡°ê±´ì„ ì…ë ¥ë°›ëŠ” í•¨ìˆ˜"""
    print("\nğŸ” ë…¼ë¬¸ ê²€ìƒ‰ ì¡°ê±´ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
    print("=" * 50)
    
    # í‚¤ì›Œë“œ ì…ë ¥
    print("\n1. ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥:")
    print("   - ì—¬ëŸ¬ í‚¤ì›Œë“œëŠ” ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•´ì£¼ì„¸ìš”")
    print("   - ì˜ˆ: usability, user experience, UX")
    keywords = input("   í‚¤ì›Œë“œ: ").strip()
    
    if not keywords:
        keywords = "usability"
        print(f"   ê¸°ë³¸ê°’ ì‚¬ìš©: {keywords}")
    
    # ì—°ë„ ë²”ìœ„ ì…ë ¥
    print("\n2. ë°œí–‰ ì—°ë„ ë²”ìœ„:")
    print("   - ì‹œì‘ ì—°ë„ë§Œ ì…ë ¥í•˜ë©´ í•´ë‹¹ ì—°ë„ ì´í›„ ëª¨ë“  ë…¼ë¬¸")
    print("   - ë²”ìœ„ ì…ë ¥ ì˜ˆ: 2020-2024")
    year_input = input("   ì—°ë„ (ê¸°ë³¸ê°’: 2020): ").strip()
    
    if not year_input:
        year_filter = "PUBYEAR > 2019"
        print("   ê¸°ë³¸ê°’ ì‚¬ìš©: 2020ë…„ ì´í›„")
    elif "-" in year_input:
        try:
            start_year, end_year = map(int, year_input.split("-"))
            year_filter = f"PUBYEAR > {start_year-1} AND PUBYEAR < {end_year+1}"
            print(f"   ì„¤ì •: {start_year}ë…„ ~ {end_year}ë…„")
        except ValueError:
            year_filter = "PUBYEAR > 2019"
            print("   ì˜ëª»ëœ í˜•ì‹ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©: 2020ë…„ ì´í›„")
    else:
        try:
            start_year = int(year_input)
            year_filter = f"PUBYEAR > {start_year-1}"
            print(f"   ì„¤ì •: {start_year}ë…„ ì´í›„")
        except ValueError:
            year_filter = "PUBYEAR > 2019"
            print("   ì˜ëª»ëœ í˜•ì‹ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©: 2020ë…„ ì´í›„")
    
    # ì–¸ì–´ ì„ íƒ
    print("\n3. ë…¼ë¬¸ ì–¸ì–´:")
    print("   1) ì˜ì–´ë§Œ (ê¸°ë³¸ê°’)")
    print("   2) ëª¨ë“  ì–¸ì–´")
    lang_choice = input("   ì„ íƒ (1 ë˜ëŠ” 2): ").strip()
    
    if lang_choice == "2":
        lang_filter = ""
        print("   ì„¤ì •: ëª¨ë“  ì–¸ì–´")
    else:
        lang_filter = "AND LANGUAGE(english)"
        print("   ì„¤ì •: ì˜ì–´ë§Œ")
    
    # ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜
    print("\n4. ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜:")
    print("   - ìµœëŒ€ 200ê°œê¹Œì§€ ê°€ëŠ¥")
    count_input = input("   ë…¼ë¬¸ ìˆ˜ (ê¸°ë³¸ê°’: 25): ").strip()
    
    try:
        count = int(count_input) if count_input else 25
        count = min(count, 200)  # ìµœëŒ€ 200ê°œë¡œ ì œí•œ
        print(f"   ì„¤ì •: {count}ê°œ")
    except ValueError:
        count = 25
        print("   ì˜ëª»ëœ í˜•ì‹ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©: 25ê°œ")
    
    # ì •ë ¬ ë°©ì‹
    print("\n5. ì •ë ¬ ë°©ì‹:")
    print("   1) ê´€ë ¨ë„ìˆœ (ê¸°ë³¸ê°’)")
    print("   2) ìµœì‹ ìˆœ")
    print("   3) ì¸ìš©íšŸìˆ˜ìˆœ")
    sort_choice = input("   ì„ íƒ (1, 2, ë˜ëŠ” 3): ").strip()
    
    sort_options = {
        "1": ("relevancy", "ê´€ë ¨ë„ìˆœ"),
        "2": ("-coverDate", "ìµœì‹ ìˆœ"),
        "3": ("-citedby-count", "ì¸ìš©íšŸìˆ˜ìˆœ")
    }
    
    sort_key, sort_desc = sort_options.get(sort_choice, ("relevancy", "ê´€ë ¨ë„ìˆœ"))
    print(f"   ì„¤ì •: {sort_desc}")
    
    return keywords, year_filter, lang_filter, count, sort_key


def build_search_query(keywords: str, year_filter: str, lang_filter: str) -> str:
    """ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ êµ¬ì„±í•˜ëŠ” í•¨ìˆ˜"""
    
    # í‚¤ì›Œë“œ ì²˜ë¦¬ - ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œë“¤ì„ ORë¡œ ì—°ê²°
    keyword_list = [k.strip() for k in keywords.split(",") if k.strip()]
    
    if len(keyword_list) == 1:
        keyword_query = f'TITLE-ABS-KEY({keyword_list[0]})'
    else:
        # ê° í‚¤ì›Œë“œë¥¼ ë”°ì˜´í‘œë¡œ ê°ì‹¸ê³  ORë¡œ ì—°ê²°
        formatted_keywords = []
        for keyword in keyword_list:
            if " " in keyword:  # ê³µë°±ì´ ìˆëŠ” í‚¤ì›Œë“œëŠ” ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
                formatted_keywords.append(f'"{keyword}"')
            else:
                formatted_keywords.append(keyword)
        keyword_query = f'TITLE-ABS-KEY({" OR ".join(formatted_keywords)})'
    
    # ì „ì²´ ì¿¼ë¦¬ ì¡°í•©
    query_parts = [keyword_query, year_filter]
    if lang_filter:
        query_parts.append(lang_filter)
    
    return " ".join(query_parts)


def search_papers_with_user_input(api_key: str) -> List[Dict]:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜
    
    Args:
        api_key (str): Scopus API Key
        
    Returns:
        List[Dict]: ê²€ìƒ‰ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
    """
    client = ScopusAPIClient(api_key)
    
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    keywords, year_filter, lang_filter, count, sort_key = get_user_search_inputs()
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
    query = build_search_query(keywords, year_filter, lang_filter)
    
    print(f"\nê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    print("-" * 80)
    
    # ì‚¬ìš©ì ì„¤ì •ì— ë”°ë¥¸ ê²€ìƒ‰ ì‹¤í–‰
    results = client.search_scopus(
        query=query,
        count=count,
        start=0,
        view="COMPLETE",  # ë” ë§ì€ ì •ë³´ í¬í•¨
        sort=sort_key
    )
    
    if not results or 'search-results' not in results:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    search_results = results['search-results']
    total_results = int(search_results.get('opensearch:totalResults', 0))
    
    print(f"ì´ ê²€ìƒ‰ ê²°ê³¼: {total_results:,}ê°œ")
    print(f"í˜„ì¬ í˜ì´ì§€ ê²°ê³¼: {len(search_results.get('entry', []))}ê°œ")
    print("-" * 80)
    
    papers = []
    
    for entry in search_results.get('entry', []):
        paper = {
            'title': entry.get('dc:title', 'N/A'),
            'authors': [],
            'publication_name': entry.get('prism:publicationName', 'N/A'),
            'publication_date': entry.get('prism:coverDate', 'N/A'),
            'doi': entry.get('prism:doi', 'N/A'),
            'scopus_id': entry.get('dc:identifier', '').replace('SCOPUS_ID:', ''),
            'cited_by_count': entry.get('citedby-count', 0),
            'abstract': entry.get('dc:description', 'N/A'),
            'subject_areas': [],
            'open_access': entry.get('openaccess', '0') == '1',
            'scopus_url': f"https://www.scopus.com/inward/record.uri?eid={entry.get('eid', '')}"
        }
        
        # ì €ì ì •ë³´ ì¶”ì¶œ
        if 'author' in entry:
            authors = entry['author'] if isinstance(entry['author'], list) else [entry['author']]
            for author in authors:
                author_name = f"{author.get('given-name', '')} {author.get('surname', '')}".strip()
                if author_name:
                    paper['authors'].append(author_name)
        
        # ì£¼ì œ ë¶„ì•¼ ì •ë³´
        if 'subject-area' in entry:
            subject_areas = entry['subject-area'] if isinstance(entry['subject-area'], list) else [entry['subject-area']]
            for subject in subject_areas:
                if isinstance(subject, dict):
                    paper['subject_areas'].append(subject.get('$', ''))
                else:
                    paper['subject_areas'].append(str(subject))
        
        papers.append(paper)
        
        # API Rate limit ê³ ë ¤í•˜ì—¬ ì ì‹œ ëŒ€ê¸°
        time.sleep(0.5)
    
    return papers


def display_papers(papers: List[Dict], top_n: int = None):
    """ê²€ìƒ‰ëœ ë…¼ë¬¸ë“¤ì„ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    
    if top_n is None:
        top_n = len(papers)
    
    print(f"\n=== ê²€ìƒ‰ëœ ë…¼ë¬¸ ëª©ë¡ (ì´ {len(papers)}ê°œ ì¤‘ ìƒìœ„ {min(top_n, len(papers))}ê°œ) ===\n")
    
    for i, paper in enumerate(papers[:top_n], 1):
        print(f"[{i}] {paper['title']}")
        print(f"    ì €ì: {', '.join(paper['authors'][:3])}{'...' if len(paper['authors']) > 3 else ''}")
        print(f"    ì €ë„: {paper['publication_name']}")
        print(f"    ë°œí–‰ì¼: {paper['publication_date']}")
        print(f"    ì¸ìš© íšŸìˆ˜: {paper['cited_by_count']}")
        print(f"    DOI: {paper['doi']}")
        print(f"    Open Access: {'Yes' if paper['open_access'] else 'No'}")
        print(f"    ì£¼ì œ ë¶„ì•¼: {', '.join(paper['subject_areas'][:3])}")
        
        # ì´ˆë¡ ìš”ì•½ (ì²˜ìŒ 200ì)
        abstract = paper['abstract']
        if abstract and abstract != 'N/A' and len(abstract) > 200:
            abstract = abstract[:200] + "..."
        print(f"    ì´ˆë¡: {abstract}")
        print(f"    Scopus URL: {paper['scopus_url']}")
        print("-" * 80)


def save_to_csv(papers: List[Dict], keywords: str, filename: str = None):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    
    if filename is None:
        # í‚¤ì›Œë“œë¥¼ íŒŒì¼ëª…ì— í¬í•¨ (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        safe_keywords = "".join(c for c in keywords if c.isalnum() or c in (' ', '_')).strip()
        safe_keywords = safe_keywords.replace(' ', '_')[:30]  # ìµœëŒ€ 30ì
        filename = f"scopus_search_{safe_keywords}.csv"
    
    # DataFrameìš© ë°ì´í„° ì¤€ë¹„
    df_data = []
    for paper in papers:
        df_data.append({
            'Title': paper['title'],
            'Authors': '; '.join(paper['authors']),
            'Publication': paper['publication_name'],
            'Date': paper['publication_date'],
            'DOI': paper['doi'],
            'Scopus_ID': paper['scopus_id'],
            'Citations': paper['cited_by_count'],
            'Open_Access': paper['open_access'],
            'Subject_Areas': '; '.join(paper['subject_areas']),
            'Abstract': paper['abstract'],
            'Scopus_URL': paper['scopus_url']
        })
    
    df = pd.DataFrame(df_data)
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"\nê²€ìƒ‰ ê²°ê³¼ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def get_advanced_statistics(papers: List[Dict]):
    """ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ í†µê³„ ì •ë³´ ì œê³µ"""
    
    if not papers:
        return
    
    print("\n=== ê²€ìƒ‰ ê²°ê³¼ í†µê³„ ===")
    
    # ì—°ë„ë³„ ë¶„í¬
    years = {}
    total_citations = 0
    open_access_count = 0
    
    for paper in papers:
        # ì—°ë„ ì¶”ì¶œ
        date_str = paper.get('publication_date', '')
        if date_str and len(date_str) >= 4:
            year = date_str[:4]
            years[year] = years.get(year, 0) + 1
        
        # ì¸ìš© íšŸìˆ˜ í•©ê³„
        citations = paper.get('cited_by_count', 0)
        if isinstance(citations, (int, str)) and str(citations).isdigit():
            total_citations += int(citations)
        
        # Open Access ë¹„ìœ¨
        if paper.get('open_access', False):
            open_access_count += 1
    
    print(f"ì´ ë…¼ë¬¸ ìˆ˜: {len(papers)}")
    print(f"ì´ ì¸ìš© íšŸìˆ˜: {total_citations:,}")
    print(f"í‰ê·  ì¸ìš© íšŸìˆ˜: {total_citations/len(papers):.1f}")
    print(f"Open Access ë¹„ìœ¨: {open_access_count/len(papers)*100:.1f}% ({open_access_count}/{len(papers)})")
    
    # ì—°ë„ë³„ ë¶„í¬ (ìƒìœ„ 5ê°œë…„)
    if years:
        print("\nì—°ë„ë³„ ë…¼ë¬¸ ìˆ˜ (ìƒìœ„ 5ê°œë…„):")
        sorted_years = sorted(years.items(), key=lambda x: x[1], reverse=True)[:5]
        for year, count in sorted_years:
            print(f"  {year}: {count}í¸")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # API Key ì„¤ì • (ì‹¤ì œ ì‚¬ìš©ì‹œ í™˜ê²½ë³€ìˆ˜ë‚˜ ì„¤ì •íŒŒì¼ì—ì„œ ì½ì–´ì˜¤ì„¸ìš”)
    API_KEY = "920a284740d2c60fc3249e6e795e928c"  # ì‹¤ì œ API Keyë¡œ êµì²´ í•„ìš”
    
    if API_KEY == "YOUR_SCOPUS_API_KEY_HERE":
        print("âš ï¸  API Keyë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        print("Elsevier Developer Portal (https://dev.elsevier.com)ì—ì„œ API Keyë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.")
        return
    
    print("ğŸ” Scopus APIë¥¼ ì‚¬ìš©í•œ ë…¼ë¬¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    try:
        # ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ë…¼ë¬¸ ê²€ìƒ‰
        papers = search_papers_with_user_input(API_KEY)
        
        if papers:
            # ê²°ê³¼ ì¶œë ¥ (ëª¨ë“  ê²°ê³¼ í‘œì‹œ)
            display_papers(papers)
            
            # í†µê³„ ì •ë³´
            get_advanced_statistics(papers)
            
            # CSV íŒŒì¼ë¡œ ì €ì¥ (í‚¤ì›Œë“œ ê¸°ë°˜ íŒŒì¼ëª…)
            keywords = input("\nì €ì¥ìš© í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (íŒŒì¼ëª… ìƒì„±ìš©): ").strip()
            if not keywords:
                keywords = "search_results"
            save_to_csv(papers, keywords)
            
            print(f"\nâœ… ê²€ìƒ‰ ì™„ë£Œ! {len(papers)}ê°œì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
        else:
            print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ë‹¤ë¥¸ í‚¤ì›Œë“œë‚˜ ê²€ìƒ‰ ì¡°ê±´ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        
def interactive_search_examples():
    """ëŒ€í™”í˜• ê²€ìƒ‰ ì˜ˆì œ ì œì•ˆ"""
    
    print("\nğŸ’¡ ê²€ìƒ‰ ì˜ˆì œ ë° íŒ:")
    print("-" * 40)
    
    examples = {
        "1. ê¸°ë³¸ ì‚¬ìš©ì„± ì—°êµ¬": {
            "keywords": "usability, user experience, UX",
            "years": "2020-2024",
            "description": "ì¼ë°˜ì ì¸ ì‚¬ìš©ì„± ì—°êµ¬ ë…¼ë¬¸"
        },
        "2. ëª¨ë°”ì¼ ì•± ì‚¬ìš©ì„±": {
            "keywords": "mobile usability, app usability, smartphone UX",
            "years": "2021",
            "description": "ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‚¬ìš©ì„± ì—°êµ¬"
        },
        "3. ì›¹ ì ‘ê·¼ì„±": {
            "keywords": "web accessibility, digital accessibility, inclusive design",
            "years": "2020-2023",
            "description": "ì›¹ ì ‘ê·¼ì„± ë° í¬ìš©ì  ë””ìì¸"
        },
        "4. ì˜ë£Œ ì‹œìŠ¤í…œ UI": {
            "keywords": "healthcare UI, medical interface, clinical usability",
            "years": "2022",
            "description": "ì˜ë£Œ ë¶„ì•¼ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤"
        },
        "5. AI/ML ì‚¬ìš©ì„±": {
            "keywords": "AI usability, machine learning UX, explainable AI",
            "years": "2020-2024",
            "description": "ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì˜ ì‚¬ìš©ì„±"
        }
    }
    
    for key, example in examples.items():
        print(f"{key}")
        print(f"   í‚¤ì›Œë“œ: {example['keywords']}")
        print(f"   ì—°ë„: {example['years']}")
        print(f"   ì„¤ëª…: {example['description']}")
        print()
    
    print("ğŸ” ê²€ìƒ‰ íŒ:")
    print("- êµ¬ì²´ì ì¸ í‚¤ì›Œë“œì¼ìˆ˜ë¡ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼")
    print("- ì—¬ëŸ¬ í‚¤ì›Œë“œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ OR ê²€ìƒ‰")
    print("- ì—°ë„ ë²”ìœ„ë¥¼ ì¢íˆë©´ ë” ì§‘ì¤‘ëœ ê²°ê³¼")
    print("- ì˜ì–´ ë…¼ë¬¸ì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ë§ì€ ê²°ê³¼ ì œê³µ")


# ì¶”ê°€ëœ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

def preview_search_results(api_key: str, query: str, count: int = 5):
    """ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ì œëª©ë§Œ)"""
    
    client = ScopusAPIClient(api_key)
    results = client.search_scopus(query=query, count=count, view="STANDARD")
    
    if results and 'search-results' in results:
        entries = results['search-results'].get('entry', [])
        total = results['search-results'].get('opensearch:totalResults', 0)
        
        print(f"\nğŸ“‹ ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ì´ {total}ê°œ ì¤‘ {len(entries)}ê°œ):")
        print("-" * 50)
        
        for i, entry in enumerate(entries, 1):
            title = entry.get('dc:title', 'N/A')[:100]
            year = entry.get('prism:coverDate', 'N/A')[:4]
            citations = entry.get('citedby-count', 0)
            print(f"{i}. [{year}] {title}... (ì¸ìš©: {citations})")
        
        return int(total)
    return 0


if __name__ == "__main__":
    # ì‹¤í–‰ ì „ ì˜ˆì œ ë³´ê¸° ì˜µì…˜
    print("ğŸ” Scopus ë…¼ë¬¸ ê²€ìƒ‰ í”„ë¡œê·¸ë¨")
    print("1) ë°”ë¡œ ê²€ìƒ‰ ì‹œì‘")
    print("2) ê²€ìƒ‰ ì˜ˆì œ ë° íŒ ë³´ê¸°")
    
    choice = input("ì„ íƒí•˜ì„¸ìš” (1 ë˜ëŠ” 2): ").strip()
    
    if choice == "2":
        interactive_search_examples()
        input("\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    
    main()


# ì‚¬ìš© ì˜ˆì œ ë° ì¶”ê°€ ê¸°ëŠ¥ë“¤

def example_advanced_search():
    """ê³ ê¸‰ ê²€ìƒ‰ ì˜ˆì œë“¤"""
    
    # ë” êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ ì˜ˆì œë“¤
    queries = {
        "ëª¨ë°”ì¼ ì•± Usability": (
            'TITLE-ABS-KEY(usability AND ("mobile app" OR "mobile application" OR smartphone)) '
            'AND PUBYEAR > 2020'
        ),
        
        "ì›¹ì‚¬ì´íŠ¸ ì‚¬ìš©ì„±": (
            'TITLE-ABS-KEY(("web usability" OR "website usability" OR "web user experience")) '
            'AND PUBYEAR > 2019 AND PUBYEAR < 2024'
        ),
        
        "ì˜ë£Œ ì‹œìŠ¤í…œ ì‚¬ìš©ì„±": (
            'TITLE-ABS-KEY(usability AND (healthcare OR medical OR "health system")) '
            'AND SUBJAREA(MEDI) AND PUBYEAR > 2021'
        ),
        
        "ê³ ë ¹ì ëŒ€ìƒ ì‚¬ìš©ì„±": (
            'TITLE-ABS-KEY(usability AND (elderly OR "older adult" OR senior OR aging)) '
            'AND PUBYEAR > 2020'
        )
    }
    
    return queries


def example_citation_analysis(api_key: str, doi: str):
    """íŠ¹ì • ë…¼ë¬¸ì˜ ì¸ìš© ë¶„ì„ ì˜ˆì œ"""
    
    client = ScopusAPIClient(api_key)
    
    # Citation Count API ì‚¬ìš©
    citation_data = client.get_citation_count(doi)
    
    if citation_data:
        print(f"DOI {doi}ì˜ ì¸ìš© ì •ë³´:")
        print(f"ì´ ì¸ìš© íšŸìˆ˜: {citation_data.get('citation-count', 'N/A')}")
    
    return citation_data