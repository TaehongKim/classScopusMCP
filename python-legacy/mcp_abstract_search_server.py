#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MCP (Model Context Protocol) ì´ˆë¡ ê²€ìƒ‰ ë„êµ¬ - ì™„ì „í•œ ì„œë²„ ë²„ì „
LLMì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë…¼ë¬¸ ê²€ìƒ‰ ë° ì´ˆë¡ ê°€ì ¸ì˜¤ê¸° ë„êµ¬
"""

import asyncio
import json
import time
import pandas as pd
import urllib3
import re
from typing import Dict, List, Optional, Any
from urllib.parse import quote

# SSL ê²½ê³  ë¹„í™œì„±í™”
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class MCPAbstractSearchTool:
    """MCP ì´ˆë¡ ê²€ìƒ‰ ë„êµ¬"""
    
    def __init__(self):
        self.scopus_api_key = "920a284740d2c60fc3249e6e795e928c"
        self.scopus_url = "https://api.elsevier.com/content/search/scopus"
        self.sources = {
            'crossref': 'https://api.crossref.org/works',
            'pubmed': 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils',
            'semantic_scholar': 'https://api.semanticscholar.org/v1'
        }
        
        self.headers = {
            'Accept': 'application/json',
            'X-ELS-APIKey': self.scopus_api_key
        }
    
    def clean_abstract(self, abstract: str) -> str:
        """ì´ˆë¡ í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not abstract or abstract == 'N/A':
            return 'N/A'
        
        # HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', abstract)
        clean_text = re.sub(r'<jats:[^>]+>', '', clean_text)
        clean_text = re.sub(r'</jats:[^>]+>', '', clean_text)
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        clean_text = re.sub(r'\s+', ' ', clean_text)
        clean_text = clean_text.strip()
        
        # ê¸¸ì´ ì œí•œ (500ì)
        if len(clean_text) > 500:
            clean_text = clean_text[:500] + "..."
        
        return clean_text
    
    def search_scopus(self, query: str, count: int = 10) -> Dict:
        """Scopus ê²€ìƒ‰"""
        params = {
            'query': query,
            'count': count,
            'start': 0,
            'apiKey': self.scopus_api_key
        }
        
        try:
            import requests
            response = requests.get(self.scopus_url, headers=self.headers, params=params, verify=False)
            
            if response.status_code == 200:
                return response.json()
            else:
                return {}
                
        except Exception as e:
            return {}
    
    def get_abstract_from_crossref(self, doi: str) -> Dict:
        """Crossref APIë¡œ ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°"""
        if not doi or doi == 'N/A':
            return {'source': 'crossref', 'abstract': 'N/A', 'success': False}
        
        url = f"{self.sources['crossref']}/{doi}"
        
        try:
            import requests
            response = requests.get(url, verify=False, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if 'message' in data:
                    message = data['message']
                    abstract = message.get('abstract', 'N/A')
                    
                    if abstract and abstract != 'N/A':
                        clean_abstract = self.clean_abstract(abstract)
                        return {
                            'source': 'crossref',
                            'abstract': clean_abstract,
                            'success': True,
                            'title': message.get('title', ['N/A'])[0] if message.get('title') else 'N/A',
                            'quality_score': 9
                        }
            
            return {'source': 'crossref', 'abstract': 'N/A', 'success': False}
            
        except Exception as e:
            return {'source': 'crossref', 'abstract': 'N/A', 'success': False}
    
    def get_abstract_from_pubmed(self, doi: str) -> Dict:
        """PubMed APIë¡œ ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°"""
        if not doi or doi == 'N/A':
            return {'source': 'pubmed', 'abstract': 'N/A', 'success': False}
        
        search_url = f"{self.sources['pubmed']}/esearch.fcgi"
        search_params = {
            'db': 'pubmed',
            'term': f"{doi}[doi]",
            'retmode': 'json'
        }
        
        try:
            import requests
            response = requests.get(search_url, params=search_params, verify=False, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if 'esearchresult' in data and 'idlist' in data['esearchresult']:
                    pmid_list = data['esearchresult']['idlist']
                    
                    if pmid_list:
                        pmid = pmid_list[0]
                        
                        fetch_url = f"{self.sources['pubmed']}/efetch.fcgi"
                        fetch_params = {
                            'db': 'pubmed',
                            'id': pmid,
                            'retmode': 'xml'
                        }
                        
                        fetch_response = requests.get(fetch_url, params=fetch_params, verify=False, timeout=10)
                        
                        if fetch_response.status_code == 200:
                            import xml.etree.ElementTree as ET
                            root = ET.fromstring(fetch_response.content)
                            
                            abstract = root.find('.//AbstractText')
                            if abstract is not None and abstract.text:
                                title = root.find('.//ArticleTitle')
                                title_text = title.text if title is not None else 'N/A'
                                
                                clean_abstract = self.clean_abstract(abstract.text)
                                return {
                                    'source': 'pubmed',
                                    'abstract': clean_abstract,
                                    'success': True,
                                    'title': title_text,
                                    'quality_score': 8
                                }
            
            return {'source': 'pubmed', 'abstract': 'N/A', 'success': False}
            
        except Exception as e:
            return {'source': 'pubmed', 'abstract': 'N/A', 'success': False}
    
    def get_best_abstract(self, doi: str) -> Dict:
        """ìµœê³  í’ˆì§ˆì˜ ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°"""
        results = []
        
        sources = [
            ('crossref', self.get_abstract_from_crossref),
            ('pubmed', self.get_abstract_from_pubmed)
        ]
        
        for source_name, source_func in sources:
            result = source_func(doi)
            if result['success']:
                results.append(result)
            time.sleep(0.3)
        
        if results:
            best_result = max(results, key=lambda x: x.get('quality_score', 0))
            return best_result
        
        return {'source': 'none', 'abstract': 'N/A', 'success': False}
    
    def search_papers_with_abstracts(self, query: str, count: int = 10) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ë…¼ë¬¸ ê²€ìƒ‰í•˜ê³  ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°"""
        results = self.search_scopus(query=query, count=count)
        
        if results and 'search-results' in results:
            total_results = results['search-results'].get('opensearch:totalResults', 0)
            entries = results['search-results'].get('entry', [])
            
            papers = []
            for entry in entries:
                doi = entry.get('prism:doi', 'N/A')
                
                # ì´ˆë¡ ê°€ì ¸ì˜¤ê¸°
                if doi != 'N/A':
                    abstract_result = self.get_best_abstract(doi)
                    abstract = abstract_result['abstract'] if abstract_result['success'] else 'N/A'
                else:
                    abstract = 'N/A'
                    abstract_result = {'source': 'N/A'}
                
                paper = {
                    'title': entry.get('dc:title', 'N/A'),
                    'authors': entry.get('dc:creator', 'N/A'),
                    'publication_name': entry.get('prism:publicationName', 'N/A'),
                    'publication_date': entry.get('prism:coverDate', 'N/A'),
                    'doi': doi,
                    'cited_by_count': entry.get('citedby-count', 0),
                    'scopus_id': entry.get('dc:identifier', '').replace('SCOPUS_ID:', ''),
                    'scopus_url': f"https://www.scopus.com/inward/record.uri?eid={entry.get('eid', '')}",
                    'abstract': abstract,
                    'abstract_source': abstract_result.get('source', 'N/A')
                }
                papers.append(paper)
            
            return papers
        else:
            return []

# MCP ì„œë²„ ì„¤ì •
tool = MCPAbstractSearchTool()

# MCP ì„œë²„ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
class MCPServer:
    def __init__(self):
        self.tool = MCPAbstractSearchTool()
    
    async def list_tools(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
        return [
            {
                "name": "search_papers",
                "description": "í‚¤ì›Œë“œë¡œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ì´ˆë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "ê²€ìƒ‰í•  í‚¤ì›Œë“œ"
                        },
                        "count": {
                            "type": "integer",
                            "description": "ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜ (ê¸°ë³¸ê°’: 10, ìµœëŒ€: 50)",
                            "default": 10
                        }
                    },
                    "required": ["query"]
                }
            },
            {
                "name": "get_abstract_by_doi",
                "description": "DOIë¡œ íŠ¹ì • ë…¼ë¬¸ì˜ ì´ˆë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "doi": {
                            "type": "string",
                            "description": "ë…¼ë¬¸ì˜ DOI"
                        }
                    },
                    "required": ["doi"]
                }
            }
        ]
    
    async def call_tool(self, name: str, arguments: dict):
        """ë„êµ¬ í˜¸ì¶œ"""
        if name == "search_papers":
            return await self.search_papers_tool(arguments)
        elif name == "get_abstract_by_doi":
            return await self.get_abstract_by_doi_tool(arguments)
        else:
            return [{"type": "text", "text": f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {name}"}]
    
    async def search_papers_tool(self, arguments: dict):
        """ë…¼ë¬¸ ê²€ìƒ‰ ë„êµ¬"""
        query = arguments.get("query", "")
        count = arguments.get("count", 10)
        
        if not query:
            return [{"type": "text", "text": "ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."}]
        
        papers = self.tool.search_papers_with_abstracts(query, count)
        
        if not papers:
            return [{"type": "text", "text": f"'{query}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."}]
        
        # ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜
        result_text = f"'{query}' í‚¤ì›Œë“œë¡œ {len(papers)}ê°œ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
        
        for i, paper in enumerate(papers, 1):
            result_text += f"[{i}] {paper['title']}\n"
            result_text += f"ì €ì: {paper['authors']}\n"
            result_text += f"ì €ë„: {paper['publication_name']}\n"
            result_text += f"ë°œí–‰ì¼: {paper['publication_date']}\n"
            result_text += f"ì¸ìš©: {paper['cited_by_count']}\n"
            result_text += f"DOI: {paper['doi']}\n"
            
            if paper['abstract'] != 'N/A':
                result_text += f"ì´ˆë¡ ({paper['abstract_source']}): {paper['abstract']}\n"
            else:
                result_text += "ì´ˆë¡: ì—†ìŒ\n"
            
            result_text += f"Scopus URL: {paper['scopus_url']}\n"
            result_text += "-" * 50 + "\n"
        
        return [{"type": "text", "text": result_text}]
    
    async def get_abstract_by_doi_tool(self, arguments: dict):
        """DOIë¡œ ì´ˆë¡ ê°€ì ¸ì˜¤ê¸° ë„êµ¬"""
        doi = arguments.get("doi", "")
        
        if not doi:
            return [{"type": "text", "text": "DOIë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."}]
        
        abstract_result = self.tool.get_best_abstract(doi)
        
        if abstract_result['success']:
            result_text = f"DOI: {doi}\n"
            result_text += f"ì œëª©: {abstract_result.get('title', 'N/A')}\n"
            result_text += f"ì´ˆë¡ ì†ŒìŠ¤: {abstract_result['source']}\n"
            result_text += f"ì´ˆë¡: {abstract_result['abstract']}\n"
        else:
            result_text = f"DOI '{doi}'ì— ëŒ€í•œ ì´ˆë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return [{"type": "text", "text": result_text}]

# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_mcp_server():
    """MCP ì„œë²„ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” MCP ì„œë²„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    server = MCPServer()
    
    # ë„êµ¬ ëª©ë¡ í…ŒìŠ¤íŠ¸
    print("1. ë„êµ¬ ëª©ë¡:")
    tools = asyncio.run(server.list_tools())
    for tool in tools:
        print(f"  - {tool['name']}: {tool['description']}")
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n2. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
    result = asyncio.run(server.search_papers_tool({"query": "artificial intelligence", "count": 2}))
    print(result[0]['text'][:200] + "...")
    
    # DOI í…ŒìŠ¤íŠ¸
    print("\n3. DOI í…ŒìŠ¤íŠ¸:")
    result = asyncio.run(server.get_abstract_by_doi_tool({"doi": "10.1016/S0014-5793(01)03313-0"}))
    print(result[0]['text'][:200] + "...")

if __name__ == "__main__":
    test_mcp_server() 